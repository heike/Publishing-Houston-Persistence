---
title: "Interactive Visualization Framework for Forensic Bullet Comparisons"
format:
  jasa-pdf:
    keep-tex: true 
    fig-pos: "H" 
    journal:
      blinded: false
  jasa-html: default
date: last-modified
author:
  - name: Nathan Rethwisch
    acknowledgements: | 
       This work was funded (or partially funded) by the Center for Statistics and Applications in Forensic Evidence (CSAFE) through Cooperative Agreement 70NANB20H019 between NIST and Iowa State University, which includes activities carried out at Carnegie Mellon University, Duke University, University of California Irvine, University of Virginia, West Virginia University, University of Pennsylvania, Swarthmore College, and University of Nebraska, Lincoln.
    affiliations:
      - name: Iowa State University
        department: Department of Statistics
  - name: Heike Hofmann
    affiliations:
      - name: University of Nebraska Lincoln
        department: Department of Statistics
abstract: |
  The current method for forensic analysis of bullet comparison relies on manual examination by forensic examiners to determine if bullets were discharged from the same firearm. This process is highly subjective, prompting the development of algorithmic methods to provide objective statistical support for comparisons. However, a gap exists between the technical understanding of these algorithms and the typical background of many forensic examiners. We present a visualization tool designed to bridge this gap, allowing for the presentation of statistical information in a more familiar format to forensic professionals. The forensic bullet comparison visualizer (FBCV) features a variety of plots that will enable the user to examine every step of the algorithmic comparison process. We demonstrate the utility of the FBCV by applying it to data from the Houston Science Lab, where it helped identify an error in the comparison process caused by mislabeling. This tool can be used for future investigations, such as examining how distance between shots affects scores. The FBCV offers a user-friendly way to convey complex statistical information to forensic examiners, aiding their understanding and utilization of algorithmic comparison methods.
keywords:
  - data visualization
  - interactive forensic modeling
  - cross-correlation function
  - land engraved area
  - forensic pattern analysis
  - forensic statistics
bibliography: bibliography.bib  
execute:
  echo: false
  warning: false
  message: false
  eval: true

---


<!-- ```{=tex} -->
<!-- \clearpage -->
<!-- \newpage -->
<!-- ``` -->

```{r citations, echo = FALSE, eval=FALSE}
# run this code chunk to update citations
keys <- rbbt::bbt_detect_citations(here::here("Writeup/Interactive-Visualization-Framework-for-Forensic-Bullet-Comparisons.qmd"))
keys <- grep("fig-", keys, invert=TRUE, value = TRUE)
rbbt::bbt_write_bib(keys=keys, 'bibliography.bib', overwrite = TRUE, library_id=rbbt::bbt_library_id('CSAFE'), translator='bibtex')
```

<!-- ```{=tex} -->
<!-- \setcounter{page}{1} -->
<!-- \pagestyle{fancy} -->
<!-- \fancyhead{}  -->
<!-- \fancyfoot{}  -->
<!-- \fancyhead[L]{\sc{Interactive Visualization Framework for Forensic Bullet Comparisons}} -->
<!-- %\fancyhead[R]{N. Rethwisch} -->
<!-- \fancyfoot[R]{\thepage} -->
<!-- ``` -->


```{r}
#| label: setup
#| echo: FALSE
#| eval: TRUE

#Loading required packages
library(dplyr)
library(ggplot2)
library(tidyverse)
library(stringr)
library(arsenal)
library(bulletxtrctr)  
library(x3ptools)
library(randomForest)
library(reshape2)
library(plotly)
library(htmlwidgets)
library(knitr)
library(patchwork)
library(kableExtra)

set.seed(1) #For barrel vs. barrel comparisons across models

#Reading the background data â€“ this process can be replicated using any comparison method. We applied a cross-correlation function to obtain these comparisons, but similar methods could be used to yield the same visualizations
main <- readr::read_csv(here::here("data/houston-all-comparisons.csv.zip"))

csafe2 <- readRDS(here::here("models/csafe_rf2.rds")) # from DIB-Hamby data/csafe2.rds
csafe3 <- readRDS(here::here("models/csafe_rf3.rds")) # from DIB-Hamby data/csafe3.rds


```

## Introduction and Background {#sec-intro}

Identifying the firearm used in a crime is a critical component of forensic examination and plays a pivotal role in criminal investigations. Ensuring evidence is appropriately identified is crucial in upholding the integrity of the criminal justice system.

Current forensic practices rely on examiners to visually inspect bullets under a comparison microscope for similarities of marks on the bullets' surfaces. As a bullet is discharged from the firearm, the rifling in the barrel forces the bullet to follow the groove pattern - like rails. Micro-imperfections in the barrel leave scratches (called *striations*) on the bullet's surface. Striations on land engraved areas (LEA; the area between two grooves) are assumed to be unique to the individual firearm. This allows forensic examiners to determine whether two bullets originate from the same source by seeing if these LEAs match [@afte]. However, this process is highly subjective, relying heavily on an examiner's expertise [@nas2009; @pcast]. These criticisms triggered the development of algorithmic comparisons [@carriquiryMachineLearningForensic2019; @chenFiredBulletSignature2019; @chuAutomaticIdentificationBullet2013; @juOpenSourceImplementationCMPS2022; @vorburgerApplicationsCrosscorrelationFunctions2011; @vorburgerTopographyMeasurementsApplications2015] to provide objective measures with the goal of augmenting an examiner's testimony.

Algorithmic comparison methods have demonstrated considerable potential to quantify the similarity between pairwise pieces of evidence. However, current approaches have created a gap between the statistical metrics and the practical understanding of these metrics by practitioners. This gap highlights the need for a more effective method to assist forensic practitioners in assessing and understanding the algorithm's performance. 

Here, we are proposing an interactive interface designed to visualize the  statistical metrics embedded in the context of the data [@wickhamVisualizingStatisticalModels2015] in a manner that is intuitive and accessible to forensic examiners. We introduce the forensic bullet comparison visualizer (FBCV). It leverages the power of interactive graphics by combining a set of interactive visualizations, allowing forensic examiners to engage with the complex algorithmic data at each stage of the process, thereby bridging the gap between statistical analysis and practical forensic application.

<!-- Interactive graphics section -->
Interactive graphics are a powerful method of analysis techniques that allow the user to dynamically explore and manipulate graphical representations of data, usually through clicking, dragging, or rescaling [@eickHighInteractionGraphics1995; @swayneIntroductionSpecialIssue1999; @urbanekIPlotsEXtremeNextgeneration2011]. A typical strategy for visualizing complex data is to use high-dimensional plots, which can incorporate multiple variables and levels of aggregation. However, these plots often pose challenges in interpretability, especially among those unfamiliar with the data [@willsLinkedDataViews2008]. To improve readability, a cogent method is to use linked data views - a type of interactive graphics that allows data views to communicate with other views. This linkage system allows for the display of highly interpretable graphs while preserving all relevant information. Users are able to select key features (1) and hide details that are less pertinent at the time (0), allowing for intuitive data exploration [@willsLinkedDataViews2008]. The FBCV leverages linked views to present data at multiple levels of the bullet analysis process.

This paper  presents a short review of the algorithmic comparison process. We then discuss the role of interactive visualizations to support diagnostics at each stage of the process. We also showcase the  diagnostic capabilities of these visuals by presenting a real-world use case where we successfully applied the FBCV to identify an error in the data-cleaning process. Finally, we highlight other ways in which the FBCV can be utilized for further investigatory analysis. 

<!-- the data -->
The data used for illustrating the process is a dataset of scans provided by a collaboration of CSAFE (Center for Statistics and Applications of Forensic Evidence) and the Houston Forensic Science Center (HFSC). The data consists of scans from 40 test fires of each of 13 Ruger LCP barrels. Ten barrels (labeled  'A' through 'J') were consecutively manufactured, while the remaining three (labeled 1-3) come from HFSC's reference library of firearms. Here, we are analyzing 40 sequential shots from each of the barrel. The lettered barrels were only fired ten times each before this study. For ease of notation, we refer to these shots as 11 through 50. LCP barrels are traditionally rifled barrels with 6 lands and 6 groove areas. These barrels mark well, i.e., striation marks are almost visible to the naked eye, making them well-suited for a forensic analysis. Scans of the bullets were obtained  by the High-Resolution Microscopy Lab at Iowa State University using a Sensofar confocal light microscope. For each bullet, 3d topographic images of each of the six land engraved areas (LEA) were acquired at 20x magnification (corresponding to 0.645 micron/pixel), resulting in a total of 3,120 LEA scans (13 barrels x 40 bullets x 6 lands).

<!-- ## Algorithmic Comparisons -->

These scans provide the basis for algorithmic comparisons.
For the processing of scans and comparison of signals, we follow the steps outlined in @hareAutomaticMatchingBullet2017, implemented in the `bulletxtrctr` package in R [@hofmannBulletxtrctrAutomaticMatching2022]. 
We apply the following steps to each of the 3,120 scans [steps 1-4] and each pair of scans [step 5]. The results from these comparisons were then rendered in our visualization framework [[@sec-visuals]].

```{r}
#| label: fig-extracted-sigs
#| fig-cap: "Signal extraction from a 3d topographic scan. From left to right we see a rendering of a 3d topographic scan of a land-engraved area, the profile corresponding to the horizontal yellow line, and the signal resulting from removing the bullet curvature from the profile."
#| out-width: '100%'
#| eval: TRUE

knitr::include_graphics("../figure/data-process.png")
```


```{r}
#| label: fig-aligned-sigs
#| fig-cap: "Aligned Signals from lands of two separate bullets."
#| fig-align: "center"
#| out-width: '65%'
knitr::include_graphics("../figure/AlignedSignals.png")

```

1.  A 3d LEA scan (left in @fig-extracted-sigs) is inspected for its suitability for comparisons, scans of low quality or of damaged lands (due to tank 'rash', pitting, or cracks) are removed from the analysis.

2.  A crosscut is chosen orthogonal to the direction of well-marked striations (marked as a yellow line in the rendering of the scan left in @fig-extracted-sigs).

3.  The topographical measurements corresponding to this crosscut are extracted from the scan. The middle plot in @fig-extracted-sigs shows the profile of these height measurements along the crosscut. The spike in height at either end of the profile indicates the start of the neighboring groove areas and need to be excluded from the comparison (values outside the vertical blue lines).  

4. The signal for a LEA (shown on the right of @fig-extracted-sigs) is created by removing the bullet curvature from the profile using a non-parametric smooth [@clevelandRobustLocallyWeighted1979].
 
5.  Finally, signals are aligned pairwise, as shown in @fig-aligned-sigs, and metrics assessing their similarity --such as the number of matching peaks, height of matching peaks,  number of consecutively matching peaks, and, more statistically, cross-correlation-- are extracted.

These metrics provide the basis of a quantifiable comparison of the strength of similarities with statistical models and algorithms. 
Common examples of such algorithms include random forests [@hofmannBulletxtrctrAutomaticMatching2022] and congruent matching profile segments [@chenFiredBulletSignature2019; @juOpenSourceImplementationCMPS2022]. A large number of these algorithms are based on the maximized cross-correlation function between pairs of signals. This is the metric which we will use in this paper. However, this is not an actual restriction, any other similarity metric would work similarly well, with its usability only restricted by the metric's diagnostic ability.

Assume that $X = \left\{X_t\right\}_{1 \le t \le N_X}$ and $Y = \left\{X_s\right\}_{1 \le s \le N_Y}$ are the observed surface measurements (signals) of two land engraved areas (with $N_X, N_Y$ the number of the respective observations). The correlation between $X$ and $Y$ is defined as the ratio of their covariance scaled by their respective variances: 
<!-- -->
$$
\text{corr} (X, Y) = \frac{\text{Cov(X, Y)}}{\sqrt{\text{Var}(X) \text{Var}(Y)}}
$$ 
$Y^{(k)}$ defines the $k$th lag of $Y$ with $Y^{(k)}_s = Y_{k+s}$ with $k \in [-M, M]$ and $0 \le M < N_Y$. The choice of $M$ depends on the minimal number of values $N_Y-M$ used as a basis for an evaluation of the similarity of the two signals. With that we define the maximized cross-correlation function $CCF_{\text{max}} (X, Y)$ as
<!-- -->
$$
CCF_{\text{max}} (X, Y) = \text{arg} \text{max}_{k \in [-M, M]} \text{corr}(X, Y^{(k)}).
$$
Here, we use $M=500$  for the alignment of signals. This corresponds to a horizontal shift of $\pm 500$ values (equal to $\pm 500 \times 0.645 \mu = .323 mm$) corresponding to about a quarter of a scan's width.


<!-- Visualization Development -->

When assessing the similarity of one bullet to another, a common approach is to assemble all scores from comparing pairs of lands in form of a square matrix and visualize it in form of a tile plot, see @fig-land-matrix. The fill color encodes the score (here, the ccf) between a pair of LEAs. Higher values indicate higher similarity, shown in shades of orange. Tiles filled with grey values indicate less similarity.  The two bullets shown in the example are known to have been fired through the same barrel. In this case, we expect six pairs of lands with high similarities (in-phase), while all other pairs (out-of phase) should result in low scores. This is exactly the pattern that can be seen in @fig-land-matrix. 

```{r}
#| label: helper-functions

#Makes the dataframe symmetric - adds the comparisons in the opposite direction
make_symmetric <- function(d) {
  houstonP2 <- d
  houstonP2$barrel1 <- d$barrel2
  houstonP2$barrel2 <- d$barrel1
  houstonP2$bullet1 <- d$bullet2
  houstonP2$bullet2 <- d$bullet1
  if ("land1" %in% names(d)) {
    houstonP2$land1 <- d$land2
    houstonP2$land2 <- d$land1
  }
  rbind(d, houstonP2)
}

#Calculates the max phase score as well as phase scores among the datasets
make_phases <- function(d){
  main <- d
  pairs <- main %>% group_by(barrel1, bullet1, barrel2, bullet2) %>% summarize(
  ccf_score = mean(ccf[samesource], na.rm = TRUE), 
  rf2_score = mean(rf2[samesource], na.rm = TRUE), 
  rf3_score = mean(rf3[samesource], na.rm = TRUE), 
  phase_ccf = ccf_score - mean(ccf[!samesource], na.rm = TRUE), 
  phase_rf2 = rf2_score - mean(rf2[!samesource], na.rm = TRUE),
  phase_rf3 = rf3_score - mean(rf3[!samesource], na.rm = TRUE)
  )
  
  return(pairs)
}


```

```{r}
#| label: fig-land-matrix
#| fig-cap: "Tile plot of all pairwise comparisons of LEA signals from two different bullets"
#| fig-align: "center"
#| fig-width: 3.15
#| fig-height: 2
#| out-width: "50%"


#Filtering the data to one barrel
barrelA <- main %>% filter(barrel1=="A", barrel2=="A", source == "houston-comparisons.csv.zip") 

#Filtering the barrel to a specific bullet pairing
houstontemp <- barrelA %>%
  filter(bullet2 == 14, bullet1 == 35)

#Creating the 6x6 tile plot
houstontemp %>%
  ggplot(aes(x = land1, y = land2, fill = ccf)) + 
  geom_tile() +
  scale_fill_gradient2(low = "grey80", high = "darkorange", 
                       midpoint = 0.5, limit = c(0, 1)) +
  scale_colour_manual(values = c("grey80", "darkorange")) +
  labs(x = "Bullet 1", y = "Bullet 2", fill = "Maximized Cross \nCorrelation") + 
  theme(
    axis.title.x = element_text(size = 8), 
    axis.title.y = element_text(size = 8),
    axis.text.x = element_text(size = 6),  
    axis.text.y = element_text(size = 6),   
    legend.text = element_text(size = 6),
    legend.title = element_text(size = 6, hjust=0.5))

```

<!-- Numerical bullet-to-bullet score -->
<!--
Numerically, we can summarise the matrix of pairwise LEA comparisons into a single statistic by calculating averages of selected comparisons. Here, we are using the (background-adjusted) maximum correlation score [@juOpenSourceImplementationCMPS2022] between bullets $B_1$ and $B_2$, given as the difference between the in-phase average and the out-of-phase average: 
 
$$
\mathrm{\overline{CCF}_{diff}}(B_1, B_2) = \underbrace{\left[  \frac{1}{n} \sum_{(i,j) \in \mathcal{P}} c_{ij}\right]}_{\text{in-phase average}} - \underbrace{\left[  \frac{1}{n(n-1)} \sum_{(i,j) \notin \mathcal{P}} c_{ij}\right]}_{\text{out-of-phase average}},
$$
-->

A summary statistic is computed using the average of in-phase scores, as these reflect bullet similarity while also being highly indicative of model performance. This is given as

$$
\mathrm{\overline{CCF}_{max}}(B_1, B_2) = \underbrace{\left[  \frac{1}{n} \sum_{(i,j) \in \mathcal{P}} c_{ij}\right]}_{\text{in-phase average}},
$$

where $c_{ij}$ is the score between land $i$ on bullet 1 and land $j$ on bullet 2, with $1 \le i, j \le n=6$, where ${\cal P}$ denotes the pairs of lands that capture the best alignment between bullets $B_1$ and $B_2$.

A pairwise comparison of $K$ number of bullets results in a set of scores of size $^KC_2 = \frac{1}{2}K(K-1)$ or $^KC_2 + K$, if we also consider to allow a comparison of a bullet to itself (done to achieve an empirical assessment of the range of scores we can expect to see for a particular type of ammunition and firearm). Different types of visualizations of these set of scores are discussed in the next section.


## Visualization Framework{#sec-visuals}

```{r}
#| label: fig-tool-pipeline
#| fig-cap: "Three connected levels of information. From left to right, there is a tile plot of scores from all bullets in one barrel, a tile plot of scores at the land-level for one pair of bullets, and a set of diagnostic plots for comparing a single pair of lands."
#| fig-align: "center"
#| out-width: "100%"
knitr::include_graphics("../figure/overview.png")

```


As seen in the previous section, there are similarity scores at the bullet-to-bullet level, there are scores at the land-to-land level, and there are important diagnostics for individual pairs of lands. For any given comparison, we have pertinent information at each of these levels (see @fig-tool-pipeline).
The statistical perspective focuses on scores within the distribution of other, comparable scores, while the focus in a forensic examination is on the individual.
The idea of this visualization tool is to connect these different levels and perspectives for a seamless exploration. 

The forensic bullet comparison visualizer (FBCV) is created in HTML using a combination of Javascript and R code. This allows us to leverage the everyday familiarity of links for implementing connections across levels of information. An implementation of the FBCV showing all comparisons involving bullets from barrel A can be found at [https://tinyurl.com/y53n3mkm](https://tinyurl.com/y53n3mkm). 

```{r}
#| label: fig-framework-interface
#| fig-cap: "Tabs in the Interface framework"
#| fig-align: "center"
#| out-width: "100%"

knitr::include_graphics("../figure/FrameworkInterface.png")
```
<!-- -->
The main interface of the FBCV consists of a set of tabs with choices for the visualization of the set of bullet scores, see @fig-framework-interface. Each tab shows an interactive visualization that focuses on a different aspect of the data, which is discussed in more detail next.
\hfill\newline

**Tile plots** are our default choice for visualizing all bullet comparisons. The left side of @fig-tilePlots shows the 40x40 matrix of all pairwise bullet comparisons in for barrel A and same-bullet scores on the diagonal. Each row and column corresponds to the bullet involved in the comparison, each cell represents the maximum phase correlation score for the respective comparison.

```{r}
#| label: fig-barrelA-tile-plot
#| fig-cap: "Tile plot of the scores of all pairwise comparisons of the 40 sequential bullets fired from barrel A"
#| fig-align: "center"
#| fig-width: 3.5
#| fig-height: 2.15
#| echo: FALSE
#| eval: TRUE

#Creating the in-phase and out-of-phase scores from a list of comparisons
houstonPairs <- make_phases(main %>% filter(source == "houston-comparisons.csv.zip"))

#Filtering to barrel A
barrelA <- houstonPairs %>% 
  filter(barrel1 == "A", barrel2=="A")

#Creating opposite comparisons in the dataframe
barrelA <- make_symmetric(barrelA)

#Creating the tile plot
matrix <- barrelA %>%
  ggplot(aes(x = bullet1, y = bullet2, fill = ccf_score)) + 
  geom_tile() +
  scale_fill_gradient2(low = "grey80", high = "darkorange", 
                       midpoint = 0.5, limit = c(0, 1)) +
  scale_colour_manual(values = c("grey80", "darkorange")) +
  scale_x_discrete(labels = NULL) +
  scale_y_discrete(labels = NULL) +
  labs(x = "Bullet 1", y = "Bullet 2", fill = "Max Phase \nCorrelation Score") + 
  theme(
        axis.title.x = element_text(size = 8), 
        axis.title.y = element_text(size = 8),
        axis.ticks = element_blank(),
        legend.title = element_text(size = 8, hjust=0.5))

```


```{r}
#| label: fig-ClusteredMatrix
#| fig-cap: "Re-ordered tile plot for barrel A scores."
#| fig-width: 4.1
#| fig-height: 2.75
#| fig-align: "center"
#| out-width: '50%'


#Filtering out the barrel and selecting what is used in the cluster
houstonPredict <- barrelA %>% ungroup() %>% select(ccf_score, bullet1, bullet2) %>% mutate(bullet1 = as.factor(bullet1), bullet2 = as.factor(bullet2))%>%unique()

#Reordering the dataframe for clustering
houstonPredict <- houstonPredict  %>%mutate(bullet1 = reorder(bullet1, ccf_score), bullet2 = reorder(bullet2, ccf_score)) %>%arrange(bullet1, bullet2)

houston_wide_a <- houstonPredict %>%
  pivot_wider(values_from="ccf_score", names_from="bullet2")

#Performing the clustering
rn <- houston_wide_a[,1]
dist_matrix <- as.dist(1-houston_wide_a[,-1])
hc <- hclust(dist_matrix, method="complete")

cut <- cutree(hc, k = 2)


#Reordering the matrix to an upper triangular matrix
houston_matrix <- as.data.frame(houston_wide_a)
makeSymm <- function(m) {
  m[upper.tri(m)] <- t(m)[upper.tri(m)]
  return(m)
}



#Making the matrix a full matrix
rownames(houston_matrix) <- houston_matrix$bullet1
houston_matrix <- houston_matrix[,-1]
houston_matrix <- makeSymm(houston_matrix)

#Reordering the matrix according to the clustering
houston_matrix <- houston_matrix[hc$order, hc$order]


#Changing the matrix back into a lower matrix
houston_matrix$bullet1 <- row.names(houston_matrix)
melted_matrix <- melt(houston_matrix, na.rm = TRUE, id = "bullet1")

#Changing the column names back to intuitive column names
colnames(melted_matrix) <- c("bullet1", "bullet2", "ccf_score")

#Plotting the newly ordered tile plot
matrixPlot <- ggplot(melted_matrix, aes(fct_inorder(bullet1),bullet2, fill = ccf_score))+
  geom_tile()+
  labs(x = "bullet1")+
  scale_fill_gradient2(low = "grey80", high = "darkorange", 
                       midpoint = 0.5, limit = c(0,1))+
  xlab("Bullet 1") + ylab("Bullet 2") + labs(fill = "Max Phase \nCorrelation Score")+ 
  scale_x_discrete(labels = NULL) + 
  scale_y_discrete(labels = NULL) + 
  theme(
    axis.title.x = element_text(size = 8), 
    axis.title.y = element_text(size = 8),
    axis.ticks = element_blank(),  
    legend.title.align = 0.5,
    legend.title = element_text(size = 8))

```

```{r}
#| label: fig-tilePlots
#| fig-cap: "Tile plots for all pairwise comparisons within a bullet"
#| fig-align: "center"
#| fig-height: 2.5
#| fig-width: 6
#| out-width: '100%'
matrix + matrixPlot + plot_layout(guides = 'collect')
```

Note that this matrix is not static: the spatial area of each tile maps interactively to the corresponding 6x6 land-to-land tile plot, such as the one in @fig-land-matrix. When a user clicks on a square in the 40x40 matrix, the FBCV retrieves the corresponding 6x6 matrix of land-to-land scores, giving users more details on the land-to-land comparisons that contribute to the score of the selected square.

The interactivity extends beyond the 6x6 matrix. By clicking on an individual square within this matrix, additional information is provided for the two LEAs and their comparison: renderings of the two LEA scans with marked crosscut locations, plots of their profiles, and the aligned signals.
These web links directly map the different levels of comparisons as shown in @fig-tool-pipeline to individual comparisons and allow the user to move naturally between abstraction levels. 

Ordering rows and columns in tile plots has a large impact on the visualization. By clicking the *Clustered* subtab, the user can view an altered version of the original 40x40 tile plot. The ordering of the rows and columns is based on a complete-linkage hierarchical clustering of the score matrix. The right size of @fig-tilePlots displays this ordering. Here, we see two fairly distinct clusters. This version of the tile plot groups bullets by their similarity, which helps to identify any significant performance discrepancies in the data. Also note that the interactivity of the clustered tile plot is the same as for the original plot.


**Scatterplots** provide an alternative representation of the scores: @fig-scatterplot shows an example of the default scatterplot. The first bullet in the comparison is represented on the x-axis, while the associated maximum phase correlation score is displayed on the y-axis. Additionally, we use color to represent the shot number of the second bullet. When the user hovers over a point, all other points containing the second bullet in the comparison are highlighted. This enables the user to identify bullets with poor scores across the dataset or those exhibiting similar patterns across all comparisons. 

```{r}
#| label: fig-scatterplot
#| fig-cap: "An interactive scatterplot for bullet comparisons"
#| fig-align: "center"
#| out-width: '60%'
# Background Code to create this interactive scatterplot
  
  
 #  barrel_name <- "A"
 #  
 #  #Adding the comparisons both ways
 #  houstonP2 <- houstonPairs
 #  houstonP2$bullet1 <- houstonPairs$bullet2
 #  houstonP2$bullet2 <- houstonPairs$bullet1
 # houstonP2 <- rbind(houstonPairs, houstonP2)
 #  
 # houstonP2$bullet2 <- as.numeric(houstonP2$bullet2)
 #  
 #  #Adding the urls to the data with the smallest bullet first
 #  houstonP2 <- houstonP2%>% mutate(urls = paste0("https://heike.github.io/Houston-Persistence/docs/Land-to-Land Grids/B", barrel_name, "-B", pmin(bullet1, bullet2), " vs.B", barrel_name, "-B", pmax(bullet1, bullet2), ".html"))
 #  
 #  #This orders the scatterplot by hierarchical clustering
 #  #houstonP2$bullet1 <- factor(houstonP2$bullet1, levels = hc$labels[hc$order])
 #  
 #  #Filtering out situations where the bullets are the same
 #  scatterData <- houstonP2 %>% filter(barrel1 == barrel_name,
 #                                       ccf_score != 1)
 #  
 #  #Creating customdata to link the urls
 #  customdata <- data.frame(
 #    bullet2 = scatterData$bullet2,
 #    urls = scatterData$urls,
 #    stringsAsFactors = FALSE
 #  )
 #  
 #  # Combine into a list for each row
 #  combined_customdata <- mapply(function(b2, url) list(bullet2 = b2, urls = url),
 #                                customdata$bullet2, customdata$urls, SIMPLIFY = FALSE)
 #  
 #  # Add combined customdata to scatterData
 #  scatterData$customdata <- combined_customdata
 #  
 #  # Creating the scatterplot
 #  scatter <-
 #    scatterData%>%
 #    ggplot(aes(x = bullet1, color = bullet2, y = ccf_score,
 #               text = paste("Correlation Score:", ccf_score, 
 #                            "<br>Bullet 1:", bullet1, 
 #                            "<br>Bullet 2:", bullet2),
 #               customdata = customdata)) + 
 #    geom_point()+
 #    labs(color = "Bullet 2")+ 
 #    xlab("Bullet 1") + ylab("Max Phase Correlation Score") + labs(fill = "Bullet 2")+
 #    theme(
 #      axis.title.x = element_text(size = 14), 
 #      axis.title.y = element_text(size = 14),
 #      legend.title.align = 0.5,
 #      legend.title = element_text(size = 12))
 #  
 #  fig <- ggplotly(scatter, tooltip = 'text', width = 900, height = 600)
 #  
 #  #Adding highlight functionality to the points
 #  fig <- fig %>% htmlwidgets::onRender("
 #    function(el, x) {
 #      var traceIndex = 0;
 #      var originalOpacity = 1;
 #      var dimOpacity = 0.1;
 #  
 #      el.on('plotly_hover', function(data) {
 #        // Get the bullet2 value from the hovered point's customdata
 #        var hoveredBullet2 = data.points[0].customdata.bullet2;
 #  
 #        // Get the current opacity of all points in the trace
 #        var currentOpacity = el.data[traceIndex].marker.opacity || [];
 #  
 #        // Create an updated opacity array where points with matching customdata are highlighted
 #        var updatedOpacity = el.data[traceIndex].customdata.map(function(customData, index) {
 #          return customData.bullet2 === hoveredBullet2 ? originalOpacity : dimOpacity;
 #        });
 #  
 #        // Update the opacity of all points
 #        var updateOpacity = { 'marker.opacity': [updatedOpacity] };
 #        Plotly.restyle(el, updateOpacity, [traceIndex]);
 #      });
 #  
 #      el.on('plotly_unhover', function(event) {
 #        // Reset all points to the original opacity
 #        var resetOpacity = { 'marker.opacity': [Array.from({ length: el.data[traceIndex].x.length }, function() { return originalOpacity; })] };
 #        Plotly.restyle(el, resetOpacity, [traceIndex]);
 #      });
 #      
 #        el.on('plotly_click', function(d) {
 #        // Get the URL from the clicked point's customdata
 #        var url = d.points[0].customdata.urls;
 #        if (url) {
 #          window.location.assign(url);  // Redirect to the URL
 #          //Call navigatetoBullet with the url and then jump to the iframe anchor for the bullet
 #          //window
 #          //window.location.href = #+anchor(name of iframe)
 #        }
 #      });
 #    }
 #  ")
knitr::include_graphics("../figure/scatterA.png")
```

Clicking on a point again brings up the 6x6 matrix of land-to-land comparisons resulting in the selected point's score.

Clicking on the *lineplot* tab brings up the same scatterplot, with the key distinction that points representing the same second bullet in the comparison are connected by a line. This visualization helps to emphasize the relationships and trends between the points that share the same bullet.
<!-- -->
\hfill\newline
**Variograms** are used to represent values as a function of the  distance. In this context, the variogram illustrates how the similarity of bullets is affected by the number of bullets fired between them, shown in @fig-variogramA. The x-axis represents the numerical distance between shots (11 vs. 12 corresponds to a distance of 1, while 11 vs. 50 is a distance of 39). The y-axis represents the algorithmic score between the bullets. The blue line shows a loess fit to capture the main trend. Clicking on any point within the variogram leads to the same interactive pipeline as the scatterplots and other visualizations.

```{r}
#| label: fig-variogramA
#| fig-cap: "The variogram included in the visualization framework"
#| out-width: '60%'

#Changing bullet numbers to integer and calculating distance
houstonPairs$bullet1 <- as.integer(houstonPairs$bullet1)
houstonPairs$bullet2 <- as.integer(houstonPairs$bullet2)

houstonPairs$bulletDistance <- houstonPairs$bullet1 - houstonPairs$bullet2

barrel_name <- "A"

#Creating the variogram plot
variogramA <- houstonPairs %>% group_by(bulletDistance) %>% 
  filter(bulletDistance > 0, barrel1 == barrel_name)%>%
  ggplot(aes(x = bulletDistance, y = ccf_score, text1 = bullet1, text2 = bullet2)) + geom_jitter(alpha = 0.5) +geom_smooth(se = FALSE, method = "loess")+
  xlab("Distance Between Shots") + ylab("Max Phase Correlation Score")+
  theme(
    axis.title.x = element_text(size = 10), 
    axis.title.y = element_text(size = 10),
    legend.title.align = 0.5,
    legend.title = element_text(size = 8))

#Displaying the variogram
variogramA
```

These visualizations are integrated into a single HTML webpage, providing a comprehensive view of the data and offering accessible insights into scores. 

## Use Cases

### The Case of Barrel D

The provided visualizations have shown scores for barrel A, but not all firearms displayed such straight-forward results. One such case was the scores for barrel D. After running the pairwise comparisons and analyzing the visualization framework, it became apparent that there was an error in the analysis for bullets 35-40. These bullets performed well when compared to each other but did not score highly compared to the other bullets shot from this firearm, as shown in @fig-matrixD. In the next section, we highlight different strategies to deal with this data discrepancy, comparing two control bullets (33-34) and the affected bullets (35-40). The bullets primarily used in this analysis are highlighted in @fig-matrixD.


```{r}
#| label: fig-tilePlotD

#Filtering to barrel D and adding opposite comparisons
barrelD <- houstonPairs %>% filter(barrel1 == "D", barrel2=="D")
barrelD <- make_symmetric(barrelD)

#Creating factors based upon the levels of unique bullets
x_levels <- sort(unique(barrelD$bullet1))
y_levels <- sort(unique(barrelD$bullet2))

barrelD <- barrelD %>%
  mutate(
    bullet1 = factor(bullet1, levels = x_levels),
    bullet2 = factor(bullet2, levels = y_levels)
  )

#Creation of the tile plot
matrix <- barrelD %>%
  ggplot(aes(x = factor(bullet1), y = factor(bullet2), fill = ccf_score)) + 
  geom_tile() +
  # Add red rectangle from x = 33 to 40 to highlight bullets in question
  geom_rect(
    xmin = as.numeric(factor(33, levels = x_levels)) - 0.5,
    xmax = as.numeric(factor(40, levels = x_levels)) + 0.5,
    ymin = 0.5,
    ymax = length(y_levels) + 0.5,
    color = "red",
    fill = NA,
    size = 1
  ) +
  scale_fill_gradient2(low = "grey80", high = "darkorange", 
                       midpoint = 0.5, limit = c(0, 1)) +
  scale_colour_manual(values = c("grey80", "darkorange")) +
  scale_x_discrete(breaks = as.character(c(11, 33, 35, 37, 40, 50)), name = "Bullet 1") +
  scale_y_discrete(breaks = as.character(c(11, 33, 35, 37, 40, 50)), name = "Bullet 2") +
  labs(x = "Bullet 1", y = "Bullet 2", fill = "Max Phase \nCorrelation Score") + 
  theme(
        axis.title.x = element_text(size = 10), 
        axis.title.y = element_text(size = 10),
        legend.title.align = 0.5,
        legend.title = element_text(size = 8))

matrixD <- matrix
```

```{r}
#| label: fig-tilePlotGrooves


#Reading in the background data and rescanned lands and grooves
  houston <- readr::read_csv(here::here("data/houston-comparisons.csv.zip"))
  houstonChanges <- readr::read_csv(here::here("data/houston-comparisons-D2.csv"))
  
   houstonChanges <- houstonChanges %>% 
    mutate(
      id1 = land1,
      id2 = land2
    ) %>%
    separate_wider_delim(
      land1, delim="-", names = c("study1", "barrel1", "bullet1", "land1")
    ) %>%
    separate_wider_delim(
      land2, delim="-", names = c("study2", "barrel2", "bullet2", "land2")
    )

  
  #Taking out the comparisons from the original scans - replacing with rescanned grooves
  houston <- houston%>%filter(barrel1 == "BD")
  houston <- houston%>%filter(!bullet1 %in% c("B33", "B34", "B35", "B36"))
  houston <- houston%>%filter(!bullet2 %in% c("B33", "B34", "B35", "B36"))
  houston <- houston[,1:38]
  
  houstonChanges <- houstonChanges%>%select(-id1, -id2)
  
  #Making the data symmetric
  houstonP2 <- make_symmetric(houstonChanges)

  houston<- rbind(houston, houstonP2)
  
  #Making the barrel information more accessible
  houston$bullet1 <- gsub("B", "", houston$bullet1)
  houston$bullet2 <- gsub("B", "", houston$bullet2)

  houston$rf2 <- predict(csafe2, newdata=houston, type="prob")[,2]
  houston$rf3 <- predict(csafe3, newdata=houston, type="prob")[,2]
  
  #Filtering out land rescans - we only want to look at the grooves
  houston <- houston %>% filter(!(land1 %in% c("L1", "L2", "L3", "L4", "L5", "L6") & bullet1 %in% c(33:36)))
  houston <- houston %>% filter(!(land2 %in% c("L1", "L2", "L3", "L4", "L5", "L6") & bullet2 %in% c(33:36)))
  
  #Making the in-phase vs. out-of-phase comparisons
  houstonPairsGrooves <- make_phases(houston)
  
  #Making the output symmetric
  houstonP2 <- make_symmetric(houstonPairsGrooves)

  #Filtering out comparisons between rescans and old scans for bullets 33-36
  houstonP2 <- houstonP2%>%filter(!(barrel1 == "BD" & barrel2 == "BD2" &
                         bullet1 %in% c(33,34,35,36) & bullet2 %in% c(33,34,35,36)))
  houstonP2 <- houstonP2%>%filter(!(barrel1 == "BD2" & barrel2 == "BD" &
                                      bullet1 %in% c(33,34,35,36) & bullet2 %in% c(33,34,35,36)))
  
  #Creating a dataframe with only the bullets of interest in these comparisons
  houstonDComparisons <- houstonP2 %>% filter(bullet2 %in% c(33:40))
  houstonDComparisons <- houstonDComparisons %>% mutate(analysisType = "Grooves")


```

```{r}
#| label: fig-tilePlotRescans

#Reading in the data with rescanned lands and grooves
houston <- readr::read_csv(here::here("data/houston-comparisons.csv.zip"))
houstonChanges <- readr::read_csv(here::here("data/houston-comparisons-D2.csv"))

  #Preprocessing the data to get variable names
  houstonChanges <- houstonChanges %>% 
    mutate(
      id1 = land1,
      id2 = land2
    ) %>%
    separate_wider_delim(
      land1, delim="-", names = c("study1", "barrel1", "bullet1", "land1")
    ) %>%
    separate_wider_delim(
      land2, delim="-", names = c("study2", "barrel2", "bullet2", "land2")
    )
  
  #Taking out the comparisons from the original scans - replacing with rescanned lands
  houston <- houston%>%filter(barrel1 == "BD")
  houston <- houston%>%filter(!bullet1 %in% c("B33", "B34", "B35", "B36"))
  houston <- houston%>%filter(!bullet2 %in% c("B33", "B34", "B35", "B36"))
  houston <- houston[,1:38]
  
  houstonChanges <- houstonChanges%>%select(-id1, -id2)
  
  #Making the comparisons symmetric
  houstonP2 <- make_symmetric(houstonChanges)
 
  
  houston<- rbind(houston, houstonP2)
  
  #Extracting bullet numbers
  houston$bullet1 <- gsub("B", "", houston$bullet1)
  houston$bullet2 <- gsub("B", "", houston$bullet2)

  houston$rf2 <- predict(csafe2, newdata=houston, type="prob")[,2]
  houston$rf3 <- predict(csafe3, newdata=houston, type="prob")[,2]
  
  #Filtering out grooves for the affected areas so we don't track both changes
  houston <- houston %>% filter(!(land1 %in% c("G1", "G2", "G3", "G4", "G5", "G6") & bullet1 %in% c(33:36)))
  houston <- houston %>% filter(!(land2 %in% c("G1", "G2", "G3", "G4", "G5", "G6") & bullet2 %in% c(33:36)))
  
  
  #Getting comparisons of in-phase vs. out-of-phase scores for both i vs. j and j vs. i
  houstonPairsRescans <- make_phases(houston)
  
  houstonP2 <- make_symmetric(houstonPairsRescans)

  #Filtering out old vs. new comparisons for bullets 33-36
  houstonP2 <- houstonP2%>%filter(!(barrel1 == "BD" & barrel2 == "BD2" &
                         bullet1 %in% c(33,34,35,36) & bullet2 %in% c(33,34,35,36)))
  houstonP2 <- houstonP2%>%filter(!(barrel1 == "BD2" & barrel2 == "BD" &
                                      bullet1 %in% c(33,34,35,36) & bullet2 %in% c(33,34,35,36)))
  
  
  #Adding to the dataframe for figure comparison
  houstonDRescans <- houstonP2 %>% filter(bullet2 %in% c(33:40))
  houstonDRescans <- houstonDRescans %>% mutate(analysisType = "Rescans")
  houstonDComparisons <- rbind(houstonDComparisons, houstonDRescans)

```

```{r}
#| label: fig-tilePlotC

#Reading in the background data and comparisons between barrels C and D
  houston <- readr::read_csv(here::here("data/houston-comparisons.csv.zip"))
  houstonChanges <- readr::read_csv(here::here("data/houston-comparisons-CD.csv"))


  #Preprocessing the data to get variable names
  houstonChanges <- houstonChanges %>% 
    mutate(
      id1 = land1,
      id2 = land2
    ) %>%
    separate_wider_delim(
      land1, delim="-", names = c("study1", "barrel1", "bullet1", "land1")
    ) %>%
    separate_wider_delim(
      land2, delim="-", names = c("study2", "barrel2", "bullet2", "land2")
    )
  
  #Filtering the data so that the original data from barrel C is replaced with barrel D
  houston <- houston%>%filter(barrel1 == "BC")
  houston <- houston%>%filter(!bullet1 %in% c("B35", "B36", "B37", "B38", "B39", "B40"))
  houston <- houston%>%filter(!bullet2 %in% c("B35", "B36", "B37", "B38", "B39", "B40"))

  houston <- houston[,1:38]
  
  houstonChanges <- houstonChanges%>%select(-id1, -id2)
  
  houstonP2 <- make_symmetric(houstonChanges)
  
  houston<- rbind(houston, houstonP2)
  
  #Extracting bullet numbers 
  houston$bullet1 <- gsub("B", "", houston$bullet1)
  houston$bullet2 <- gsub("B", "", houston$bullet2)

  
  houston$rf2 <- predict(csafe2, newdata=houston, type="prob")[,2]
  houston$rf3 <- predict(csafe3, newdata=houston, type="prob")[,2]
  
  # #Filtering out grooves for the affected areas so we don't track both changes from the rescans dataset
  # houston <- houston %>% filter(!(land1 %in% c("G1", "G2", "G3", "G4", "G5", "G6") & bullet1 %in% c(35:40)))
  # houston <- houston %>% filter(!(land2 %in% c("G1", "G2", "G3", "G4", "G5", "G6") & bullet2 %in% c(35:40)))
  
  #Getting in-phase vs. out-of-phase scores
  houstonPairsC <- make_phases(houston)
  
  #Obtaining i vs. j and j vs. i comparisons
  houstonP2 <- make_symmetric(houstonPairsC)

  houstonP2 <- rbind(houstonPairsC, houstonP2)
  
  #Filtering out comparisons between barrel C and D for the replaced bullets
  houstonP2 <- houstonP2%>%filter(!(barrel1 == "BD" & barrel2 == "BC" &
                         bullet1 %in% c(35,36,37,38,39,40) & bullet2 %in% c(35,36,37,38,39,40)))
  houstonP2 <- houstonP2%>%filter(!(barrel1 == "BC" & barrel2 == "BD" &
                                      bullet1 %in% c(35,36,37,38,39,40) & bullet2 %in% c(35,36,37,38,39,40)))
  
  #Adding to the dataframe for visualization
  houstonC <- houstonP2 %>% filter(bullet2 %in% c(33:40))
  houstonC <- houstonC %>% mutate(analysisType = "Tile Plot C")
  houstonDComparisons <- rbind(houstonDComparisons, houstonC)
  
```

```{r}
#| label: fig-matrixD
#| fig-height: 3.5
#| fig-width: 5
#| fig-cap: "Tile plot of pairwise comaprisons for barrel D"

matrixD

```


```{r}
#| label: fig-matrixDAdjustments
#| fig-cap: "Overview of the adjustments made throughout the data cleaning process and their impact on the matrices"
#| fig-height: 4
#| fig-width: 10.5

#Creating a tile plot for all of the rescan analysis
 matrixRedo <- houstonDComparisons %>%
  ggplot(aes(x = factor(bullet1), y = factor(bullet2), fill = ccf_score)) +
  geom_tile() +
  facet_grid(analysisType ~ .)+
  scale_fill_gradient2(low = "grey80", high = "darkorange",
                       midpoint = 0.5, limit = c(0, 1)) +
  scale_colour_manual(values = c("grey80", "darkorange")) +
  scale_x_discrete(
    breaks = as.character(c(11, 15, 20, 25, 30, 33, 35, 37, 40, 45, 50)),
    name = "Bullet 1"
  ) +
  scale_y_discrete(
    breaks = as.character(c(11, 33, 35, 37, 40, 50)),
    name = "Bullet 2"
  ) +
  labs(x = "Bullet 1", y = "Bullet 2", fill = "Max Phase \nCorrelation Score") +
  theme(
    axis.title.x = element_text(size = 10),
    axis.title.y = element_text(size = 10),
    legend.title.align = 0.5,
    legend.title = element_text(size = 8)
  ) +
  coord_fixed()+
  theme(panel.spacing = unit(1, "lines"))
 
 
matrixRedo


```


**Comparing Groove-Engraved Areas** 

One potential reason for this suboptimal performance may stem from the groove-engraved areas (GEAs) being scanned rather than the land-engraved areas. Note that these areas are usually not used for examinations because grooves preserve marks from the tool they are made.  When firearms are manufactured, a broaching tool is used to create the grooves for the rifling. This incorporates marks specific to the tool on the surface of the barrel. Because the same broaching tool is used for multiple barrels, marks on grooves are not specific to the firearm, limiting the ability to conclusively link striations on groove-engraved areas of a bullet to a particular firearm.

::: {#fig-bulletScans layout-ncol="2" fig.pos="H"}
![Original land from bullet 35](../figure/HFSCP-BD-B35-L2.png){#fig-LEA35}

![Scan of a groove from bullet 35](../figure/HFSCP-BD2-B35-G2-Cropped.png){#fig-GEA}

Comparing the land-engraved area and the groove-engraved area of bullet 35 from barrel D.
:::

When analyzing the scans of groove-engraved areas (GEAs), it became apparent that the usage of grooves was not the root of the problem. @fig-LEA35 below shows the original scan from Bullet 35, while @fig-GEA shows a rescanned groove for that same firearm. Notably, the scan from GEAs has fewer topographical protrusions than the original image, indicating a smoother surface profile.

We then conducted an analysis where bullets 33-36 in the original data were replaced with comparisons using the grooves. For this test, bullets 33 and 34 act as a control - they represent scans that were already producing expected results in the dataset. Bullets 35 and 36 represent two bullets performing poorly in barrel D. The matrix of affected bullets was recreated using our interactive framework, shown in the left plot of @fig-matrixDAdjustments.

This visualization reinforces the conclusion that the discrepancy in the max phase correlation score was not due to grooves being scanned instead of lands. Not only are bullets 35 and 36 performing worse than before, but the scores on our control bullets - 33 and 34, also dropped significantly. Thus, we can conclude that the inaccuracy of the original data is not because groove areas were analyzed instead of lands.

\hfill\newline\noindent
**Rescanning Land-Engraved Areas**\hfill\newline
<!-- -->
Our following action was to rescan and process the 3D topographical imaging on the bullets in question. The same control and test groups were used as the groove comparisons. Bullets 33 - 36 were rescanned, with 33 and 34 as the control. Replacing those comparisons in the interactive framework showed a drastic difference in results. In the matrix, the max phase correlation scores of the rescanned bullets aligned closely with those the other bullets fired from firearm D, shown in the middle plot of @fig-matrixDAdjustments. Furthermore, no significant change was found in the scores of the control group. When utilizing other parts of the FBCV, such as the 6x6 matrix and looking at the raw scans, these comparative results were reinforced. The alignment of signals for the rescans showed significant improvement compared to the previous alignment among barrel D.

Thus, the observed discrepancy in performance stems not from the algorithmic process itself but from inconsistencies in the raw scans utilized in the initial data processing. This could be due to various factors, including mislabeling or inadequate scanning. However, if this is a case of mislabeling scans, it raises questions regarding the provenance of the original scans.
<!-- -->
<!-- -->
\hfill\newline\noindent
**Closing the Loop**\hfill\newline
<!-- -->
To answer whether the data was mislabeled, we compared the original scans of bullet D to data obtained from all of the 12 other firearms in the Houston dataset. We selected one bullet from each firearm that performed exceptionally compared to the other bullets from that firearm (12 bullets in total). Those bullets were then compared to both each other and bullet 39 from firearm D, one of the originally poor-performing bullets.

We found that 11 of the 12 bullets showed poor performance when compared to the selected bullet from firearm D. The exception was the bullet selected from firearm C. When comparing that bullet to bullet 39 of barrel D, the algorithmic results showed that the two bullets were likely fired from the same weapon. @fig-CD-Comparison shows the 6x6 matrix from our framework tool when comparing the selected bullet from firearm C to bullet 39 of barrel D. The alignment between these two bullets is extremely strong, even stronger than many other bullet comparisons where both bullets originated from firearm C.

```{r}
#| label: fig-CD-Comparison
#| fig-cap: "Replacing 6x6 tile plot from bullet C with bullet D"
#| fig-align: "center"
#| fig-height: 2.25
#| fig-width: 3.5
#| echo: FALSE
#| warning: FALSE
#| message: FALSE

#Filtering the data to the comparisons between barrels
twobullets <- main %>% 
  filter(source == "houston-comparisons-goodBullets.csv") %>%
  filter(barrel1 == "D", barrel2 == "C")

#Getting predicted same source by the highest in-phase score
twobullets$samesource <- bullet_to_land_predict(twobullets$land1, twobullets$land2, twobullets$rf2, difference = 0, alpha = 0.5)

#Tile plot of barrel C bullet vs. misperforming barrel D bullet
twobullets %>%
  ggplot(aes( x = land1, y = land2, fill = ccf)) +
  geom_tile() +
  scale_colour_manual(values = c("grey80", "darkorange")) +
  geom_tile(size= 1, data = twobullets%>% filter(samesource)) +
  scale_fill_gradient2(low="darkgrey", high = "darkorange", mid="white", midpoint=0.5, limit = c(0,1))+
  labs(x = "Bullet 1", y = "Bullet 2", fill = "Maximized Cross \nCorrelation") + 
  theme(
        axis.title.x = element_text(size = 8), 
        axis.title.y = element_text(size = 8),
        axis.text.x = element_text(size = 6),  
        axis.text.y = element_text(size = 6),   
        legend.text = element_text(size = 6),
        legend.title = element_text(size = 6, hjust=0.5))
```

It is also important to note that the selected bullets did not perform well when compared with each other (i.e., results from the chosen bullet from firearm A did not match the bullet from firearm B). This implies the similarity between the selected bullet from firearm C and the poor-performing bullet from firearm D cannot be attributed to well-performing bullets being accurate among comparisons with other weapons. Thus, we have strong evidence that the bullets were mislabeled, with the poorly performing bullets originating from barrel C.

This notion is strengthened by our visualization tool. When the comparisons for bullets 35-40 are substituted with those initially labeled as bullets 35-40 fired by barrel D, there is no significant deviation in performance according to the matrix shown in the right plot of @fig-matrixDAdjustments. While there may appear to be a dip in performance around this area, the differentiation happens in bullets 34-37, which is not the complete scope of the substituted bullets. Overall, these scans perform very well compared to other bullets shot by firearm C. Thus, we can conclude that bullets 35-40 were mislabeled and shot by firearm C, not D.

### Bullet Distance Analysis

A key focus of this tool was evaluating whether model performance changes as more bullets are fired from a weapon. Using variograms, we provided a visual representation of this performance. A variogram is a geostatisitical tool used to visualize spatial dependence. In our context, spatial dependence refers to the relationship between model performance and distance (i.e., number of shots) between selected bullets. @fig-variograms illustrates variograms for all firearms in the Houston dataset. Note that poor-performing bullets from barrel D were removed in this analysis, as well as two bullets from barrel J that displaying similar performance issues. Future analysis will investigate the underlying cause of these discrepancies in bullet J.


```{r}
#| label: fig-variograms
#| fig-cap: "Variograms across all firearms"
#| fig-align: "center"
#| fig-height: 7
#| fig-width: 8

#Filtering out bullets 35-40 in barrel Ddue to aforementioned issues
houstonPairsFiltered <- houstonPairs %>% filter(!((barrel1 == "D" & barrel2 == "D") &
                                                  (bullet1 %in% c(35:40) | bullet2 %in% c(35:40))))

#Filtering out bullets 46 and 50 in barrel J due to performance issues
houstonPairsFiltered <- houstonPairsFiltered %>% filter(!((barrel1 == "J" & barrel2 == "J") &
                                                    (bullet1 %in% c(50, 46) | bullet2 %in% c(50,46))))

#Computing mean scores for each bullet distance and barrel
mean_scores <- houstonPairsFiltered %>%
  filter(bulletDistance > 0) %>%
  group_by(barrel1, bulletDistance) %>%
  summarise(mean_ccf = mean(ccf_score, na.rm = TRUE), .groups = "drop")

#Creating a variogram to anlayze bullet distance
ccf_variograms <- houstonPairsFiltered %>%
  filter(bulletDistance > 0) %>%
  ggplot(aes(x = bulletDistance, y = ccf_score)) +
  geom_point(alpha = 0.3)+
  facet_wrap(~barrel1) +
  labs(x = "Bullet Distance", y = "Max Phase Correlation Score") +

  # Adding in mena points
  geom_point(data = mean_scores, aes(x = bulletDistance, y = mean_ccf), 
            color = "#FF4500", size = 1.2) +

  # Add linear model fit to the means
  geom_smooth(data = mean_scores, aes(x = bulletDistance, y = mean_ccf), 
              method = "lm", se = FALSE, color = "#00BFFF")
  
ccf_variograms

```

A linear model was fit to each of the individual bullets. The formula for the linear model can be defined as: 

<!-- -->
$$
\widehat{\text{CCF}_{\max}}(B_1, B_2) = \theta_0 + \theta_1 \times \frac{1}{N(d)} \sum_{i=1}^{N(d)} \text{CCF}_{\max}^i(B_1, B_2)
$$
where $d = \lVert B_2 - B_1 ||$, 
$N(d)$ is the number of observations at a given distance, and
$i$ is the $CCF_{max}$ between $B_2$ and $B_1$ at a given $d$.
$\theta_1$ represent the change in mean $CCF_{max}$ score of bullets at a given $d$. 

@fig-variogramCoefficients shows the coefficients for each bullet's fitted line.


```{r}
#| label: fig-variogramCoefficients
#| fig-cap: "Coefficients for a fitted variogram line"
#| fig-align: "center"
#| fig-height: 2
#| fig-width: 3

#Splitting the data by barrel
split_data <- split(mean_scores, mean_scores$barrel1)

# Fit a linear model and printing out the coeficients
model_output <- lapply(split_data, function(df) {
  model <- lm(mean_ccf ~ bulletDistance, data = df)
  coef(model)
})


# Model table for output
model_table <- data.frame(
  barrel = names(model_output),
  intercept = sapply(model_output, function(x) round(unname(x[1]), 5)),
  slope = sapply(model_output, function(x) round(unname(x[2]), 5))
)

# Outputting the table
kable(model_table, col.names = c("Barrel", "$\\theta_0$", "$\\theta_1$"), align = "lrrl", row.names = FALSE, format = "latex", escape  = FALSE) %>%
  kable_styling("striped", full_width = TRUE)

```

We hypothesized that model performance would decline as the distance between shots fired increases. This does appear to be the case in some firearms, specifically firearms 2, D, and J. However, among all bullets, $\theta_1$ is relatively small, no higher than $|0.00268|$ Combined with the visual analysis of the variogram, it is reasonable to conclude that bullet distance has minimal effect on model accuracy. This is especially reasonable when $d < 30$, where we have a large number of data points.

However, we acknowledge that there is significant variability among the in-phase scores across the firearms we examined. This variability suggests that additional factors beyond bullet distance have a substantial effect on model performance and accuracy. Potential factors may include, but are not limited to, inconsistencies in bullet scan accuracy, slight differences in ammunition characteristics, and differences in the way in which a firearm was discharged, may also play a key role in observed variability. These factors prompt further investigation to determine their role in achieving consistent model predictions and reducing variability among bullets.

## Discussion

### Key Findings
The FBCV was proven effective in identifying an error in the highlighted dataset. Through a series of interactive visualizations, we identified the cause of the performance issues, which was attributed to labeling error. Through a series of rescans, we resolved the error, allowing us to move forward with the analysis. This demonstrates the practical use of the FBCV in error identification.

The FBCV also includes variograms, which allow for insightful analysis on how bullet distance affects model accuracy. Using these visualization tools, we examined the impact on 13 different firearms. By fitting a line to the mean in-phase score at each distance among variograms, we observed that model accuracy does not significantly degrade with increasing bullet distance. However, the variability of bullet scores is high, indicating other factors have a substantial effect on prediction performance outside of how many shots were fired between bullets. The plots included in the FBCV offer a promising tool for future analysis on additional datasets, which could contribute to expanding the literature in this area.

### Limitations
This study faces a number of limitations, chiefly regarding file storage. Because of the large number of comparisons, a considerable amount of files were rendered for each stage in the FBCV's process. Each firearm contains 1600 bullet-to-bullet comparisons. Then, for each bullet-to-bullet comparison, there are 36 sub-comparisons made at the land level, corresponding to the six lands of each bullet. Therefore, we must process $1600 \times 36 = 57,600$ png images at the land level.

At the lowest level of the FBCV, an image is processed for each pf the lands being compared, the cutoffs of the LEA for both lands, and the aligned signals. Therefore, 288,000 background PNG files are processed before they are aggregated into HTML format. To mitigate the storage burden, we employed a strategy to avoid creating new background files for each HTML rendering. For the 40x40 matrix, the 6x6 land-to-land matrix, and the bullet comparison informational HTML, we used a single background file for each type of HTML. This background file was reused across different comparisons, enabling more efficient rendering of the FBCV without duplicating files for each individual bullet comparison.

Despite these adjustments, the substantial number of files presents a significant storage challenge, and Github was unable to accommodate more than the number of files associated with one firearm. Consequently, the figures presented in this analysis primarily focus on firearm A. Furthermore, the need to render such a large number of files complicates the process of making rapid updates to the scans, as any modification typically requires re-rendering a large number of figures. Still, as demonstrated in previous examples, the framework does allow for updates as changes are introduced.

## Conclusion

This paper presented an interactive framework for analyzing algorithmic comparisons of whether two bullets were fired from the same firearm. The framework includes various visualizations that allow the user to assess algorithmic performance at a broader scope while also diagnosing issues at every level of the comparative analysis process. The FBCV was used to analyze algorithmic performance on the Houston dataset. It successfully identified a problematic error in the comparison process, and investigative steps were taken to discern the cause of the error, which is attributed to mislabeling. In the future, this visualization framework can provide summary overviews of algorithmic performance and diagnose problems in the data processing of forensic bullet analysis. By offering an interface that is intuitive and accessible, it presents an option that can support forensic examiners and lead to more accurate forensic analysis.

